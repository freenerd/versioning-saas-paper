\section{Architecture (Johan)}
\label{sec:architecture}

In this section we first clarify the \emph{application stack} we are assuming the SaaS application to have. Then we explain the different architectural approaches to implement versioning of SaaS, with \emph{multi-instance} as well as \emph{shared-instance} on the different application stack layers.

One important assumption we make for versioning is, that each tenant and therefore also all users of a tenant use the same version at the same time. Practially this means that each tenant has a dedicated migration point in which they decide to switch their version. This switch affects all their users at the same time. Users aren't allowed to individually choose their version.

We furthermore assume that alls requests to the SaaS are authenticated, thus there is a user associated with each request. Since we have a tenant-based system, this will likely be the standard.

\subsection{Application stack}

\begin{wrapfigure}{r}{0.4\textwidth}
\centering
\includegraphics[width=0.4\textwidth]{stack.pdf}
\caption{Simplified Application Stack}
\label{fig:stack}
\end{wrapfigure}

To understand the architecture better, we first want to look at the SaaS application stack as displayed in Figure~\ref{fig:stack}. We derived this stack from our experience with developing SaaS ourselves as well as stacks we have seen in related papers (as depicted earlier in Section~\ref{sec:relatedwork}).

We assume a separation between the front-end, back-end and database layer. The \emph{front-end layer} is mainly concerned with the user interface. In a SaaS it will usually be delivered to the user's browser within a request/response cycle. Another case for the fron-end layer are native application that communicatie with the SaaS over a webservice API. We handle this more in-depth in Section~\ref{sec:sharedfrontend}. The \emph{back-end layer} is concerned with the application and business logic. It takes requests from the front-end layer and accordingly communicated with the \emph{database layer}. The front-end and back-end layers are stateless (mostly for being able to scale horizaontally). All state is kept in the database layer.

To focus our research, we omitted some details of the stack. First we were not concerned with neither caching nor load balancing. Furthermore we omitted how user management is done, especially with regards to authentication.

\subsection{Multi-instance}

\begin{figure}
\centering
\includegraphics[width=\textwidth]{multiinstance.pdf}
\caption{Example for a version-supporting Multi-Instance Architecture}
\label{fig:multiinstance}
\end{figure}

In a multi-instance architecture the whole application stack is deployed several times on distinct resources. You can see an example in Figure~\ref{fig:multiinstance}. Usually the multi-instance architecture serves the purpose of provisioning resources for each tenant individually for horizontal scaling as well as being able to develop a single-tenant application instead of having to do the engineering overhead of developing a multi-tenant application. This approach can also be used for versioning, where we see two variants:

\paragraph{Single instance per tenant} When every tenant has their own application stack instance running, these instances can be versioned by deploying the respective software version on the tentant's instance.
\paragraph{Single instance per version with multiple tenants} When every instance has a specific version, the instances in turn can be hosts for multiple tenants by using the shared-instance mechanisms explained in the following section.

Using a multi-instance architecture has the benefits that it is the most 'natural way' to provide a SaaS, since the developer does not have to deal with issues concerning multi-tenancy in one instance, like vertical scaling or isolation. Among the drawbacks are that multi-instance has a bad resource consolidation factor, thus if e.g. one tenant uses many resources but another uses none, the unused resources can't be allocated to the spiking tenant easily. Also the maintentance cost increases with the numer of tenants and there is no economy of scale working in favor of the SaaS provider here.

Versioning-wise the actual application stack is not version-aware and thus can be built without versioning as a concern. Instead versioning is handled on the deployment level. Migrations between versions might then need significant operations engineering effort.

\subsection{Shared-instance}

The shared-instance architecture consist of one software stack deployment that serves all tenants at the same time. This architecture is the one that is generally referred to when talking about SaaS applications, since it uses the economy of scale well due to its high consolidation factor \cite{Mietzner2009} \cite{Bezemer2010} \cite{Chong2006}.

To investigate versioning in the shared-instance architecture, we will individually inspect the layers of the application stack as outlined in the previous section, consisting of the front-end, back-end and database layer. For each layer we will outline how versioning can happen. We are closing this section with a look at migrating between versions.

\subsection{Shared-instance: Front-end layer}
\label{sec:sharedfrontend}

We split the \emph{front-end layer} into two categories: a \emph{web-application} running in the user's browser and an \emph{API consumer} e.g. running on the user's mobile phone.

\subsubsection{Web application} In web applications the user's browser is usually reloading the whole web page on each request, which usually stems from an interaction of the user with the system\footnote{We assume that caching works transparently and perfectly as well as "One page applications" reloading their assets automatically ("hot code reload") in case something on the back-end layer changes.}. Thus there is a thight couling between the front-end and the back-end, from which we conclude that they are both versioned simultaneously. Since the front-end software is delivered to the user's browser on each request, the versioning concern can be completely handled on the \emph{back-end layer} as outlined in the next section.

\subsubsection{API consumer} To allow programmatic access to the SaaS functionality, SaaS providers usually implement a webservice. A common occurance are HTTP APIs following the REST principles \cite{Fielding2000}. These APIs allow native applications (e.g. mobile phone applications) or other webservices to build on top of the SaaS. The SaaS and their API consumers are loosly coupled. They follow own product cycles. In case of compatibility breaking changes in the SaaS API, the API consumers have to adapt to the changes and deploy a new version to their users. This might be hard to do e.g. because users might be reluctant to updates, delivery cycles might be too long or the API consumer developer might not have the resources to update their product. This leads us to the conclusion that SaaS APIs should be able to provide several versions of the API at the same time. The API consumer chooses which version of the API they want to use. There are many ways to handle versioning APIs and explaining them in-depth is over the scope of this report. Examples are version numbers in the URL or \emph{HTTP Accept Header} of a request \cite{RFC2616}, or feature flags for the consumer application in the SaaS \cite{playbook2013}.

  % Frontend API Versioning
  %   In URL:
  %     http://api.com/v1/resource.json?version=1
  %   Accept Header:
  %     Accept: application/json+v1
  %   Application Flag:

\subsection{Shared-instance: Back-end layer}

In versioning the back-end layer we are exploring two variants: \emph{1:1} and \emph{1:n}.

\subsubsection{Shared-instance with 1:1 mapping}

\begin{figure}
\centering
\includegraphics[width=\textwidth]{sharedinstance11.pdf}
\caption{Example for a shared-instance architecture with 1:1 mapping}
\label{fig:sharedinstance11}
\end{figure}

The \emph{1:1 mapping} depicts that each product version is mapped to one code revision. Figure~\ref{fig:sharedinstance11} shows the architecture. Thus to support different product versions at the same time, the respective code revisions have to be deployed on different back-end servers. On each request, the user management decides to which back-end servers the request is routed, depending on the tenant the user belongs to.

The benefit of this approach is, that the versioning is happening outside of the application code, thus the code does not have to be version-aware. On the downsides, the consolidation factor of this approach is low, given that the load is split between non-consolidateable versions. This defecit increases with the increase of versions running in parallel. Furthermore this leads to a heterogeneous deployment which is more complex than a homogeneous deployment.  Also this can lead to problems like bugfixes, that if written once have to be merged and deployed into every running version. Also this approach needs an intelligent routing layer (in our example above the user management) which decides on which app server to map which request.

% a product ver = code rev
%
% Pro
% Versioning is external to application code
%
% Contra
% worse consolidation factor
% intelligent routing layer needed
% heterogeneous deployment
% forking of code base makes security patches difficult to apply

\subsubsection{Shared-instance with 1:n mapping}

\begin{figure}
\centering
\includegraphics[width=\textwidth]{sharedinstance1n.pdf}
\caption{Example for a shared-instance architecture with 1:n mapping}
\label{fig:sharedinstance1n}
\end{figure}

The \emph{1:n mapping} depicts that each app server can serve requests for all of the \emph{n} available versions. Figure~\ref{fig:sharedinstance1n} shows the architecture. The choice of which version to serve is on the app server, implemented with feature switches. Listing~\ref{1ncode} shows a code example in Ruby. In the beginning of this section we assumed that every request has a user attached to it. Furthermore we assumed that all users of a tenant share the same version, which leads us to the assumption that the current version for each user will be saved in the backend and be available during runtime.

\lstset{language=Ruby, caption=Example code for \emph{1:n mapping} on an applicaiton server, label=1ncode}
\begin{lstlisting}
  if user.has_version?("1.0")
    do_something()
  end

  if user.has_version?("1.1")
    do_something_a_bit_different()
  end
\end{lstlisting}

The \emph{1:n mapping} approach has several benefits: The consolidation factor is high, since all app servers can serve all requests. The deployment is homogeneous over the app servers, thus making operations easier. Also it is possible to version more fine-grained, not only based on product versions but actually on feature level and even feature version.

On the downside, the feature switches in the code increase code complexity, which might increase development time and increases the probability of bugs. Also the feature switches are spread over the code and removing them needs software development effort. Thus abandoning old versions is connected with extra cost.

% Pro
% good consolidation
% homogenous deployment
% more flexibility: fine grained feature selection
%
% Contra
% increased code complexity, might lead to more bugs
% high cost for abandoning old version to clean code base
%
%
% inside of code base are many version checks "if version == 1.4 ..."
% more flexibility in choosing version, maybe not choose version but choose only features

\subsection{Shared-instance: Database}

The database is where state is kept. We assume that the database is in the style of a relational database, in that it keeps the data in tables with specified schemas to ensure the format and validitiy of the data.

In this section we will differentiate between two major cases reagarding the database when versioning SaaS: \emph{Different versions share the same datbase schema} and \emph{different versions need separate schemas}.

\subsubsection{Different versions share same schema}
% TODO nice diagram?

When different versions share the same database schema, the database is actually agnostic to versioning. The changes of the versions happen in the other layers and thus never propagate down to the database.

\subsubsection{Different versions need separate schemas}
% TODO nice diagram?

When schemas change between versions, the database shares the concern of versioning. Given that we assume we are dealing with a schema-based database management systems, the question is: How can database schemas be versioned? How can a database support several schemas for the same data at the same time?

In our research we did not found a database that prodvides version-aware schemas. We investigate this option more in Section~\ref{sec:futurework}.

% TODO materialized views? i remember some research about making them writeable as well ...

Since the database can not handle the versioning concern, the responsibility is pushed up in the stack to the back-end layer. Next we will investigate two approaches for that.

\paragraph{Different tables for each schema}

To store different schemas, a new database or table can be created for each version. An example with different tables can be seen in Listing~\ref{differenttablessql}. Each tenant is on a specific version, thus their data is stored in the table for their respective version.

\lstset{language=SQL, caption=sql, label=differenttablessql}
\begin{lstlisting}
  create table users_v1;
  create table users_v2;
  create table users_v3;
\end{lstlisting}

% TODO: Ich bin von den Pro/Cons nicht so richtig überzeugt
% Pro:
% Works well if not too many versions
%
% Con:
% Messy design if many versions

\paragraph{Pivot tables}

\begin{figure}
\centering
\includegraphics[width=\textwidth]{pivot.png}
\caption{Schema of pivot tables as shown in \cite{Yaish2011}}
\label{fig:pivot}
\end{figure}

Pivot tables as explained in \cite{Yaish2011} \cite{Aulbach2011} \cite{Weissman2009} follow the idea of not using a fixed schema in the database but keeping a flexible schema in the application. The database gets reduced to a more simple key-value store. An example can be seen in Figure~\ref{fig:pivot}.

\subsubsection{Migration of data}

When a tenant decides that they want to move to a new version and the version switch changes the schema, then the data of the tenant has to be migrated from the old to the new schema. Next we will describe two ways for running migrations:

\paragraph{Batch-processing migration} The data is migrated in one go. Depending on the database management system, the schema changes and the amount of data, this process might take significant time. Depending on the algorithm used to execute the migration, the database might be completely unavailable for that tenant's users during the migration or be in a read-only state.

\paragraph{On-the-fly migration} The data is migrated when it is requested or written. This could mean that clusters of data are migrated in batch (e.g. a user is migrated when she logs in) or are migrated row-by-row.

% version is chosen per tenant
% data migrations need time
% data migrations might need downtime
% on-the-fly migrations possible
